# MSIC-Bench: A Systematic Benchmark for LLM Clinical Reasoning in MSI Oncology

This repository contains the official resources for our paper: **"Augmenting Large Language Models with a curated knowledge base transforms unsafe fabrication into reliable clinical reasoning in an oncology benchmark"**.

## About The Project

MSIC-Bench is a novel, two-tiered benchmark designed to systematically evaluate the clinical reasoning capabilities of Large Language Models (LLMs) in the complex domain of Microsatellite Instability (MSI) cancer. It addresses the critical need for a standardized evaluation framework to ensure the safety and reliability of LLMs in specialized clinical settings.

Our key findings demonstrate that:
*   The primary bottleneck for current LLMs is **insufficient domain knowledge**, not flawed reasoning.
*   **Retrieval-Augmented Generation (RAG)** is a critical intervention that not only improves accuracy but also transforms model errors from unsafe "fabrication" to safer "cautious refusal".

## Getting Started

The code and data for MSIC-Bench are currently undergoing final refactoring and documentation. We are committed to open science and plan to release all resources publicly upon the paper's publication.

**Stay tuned for updates!**

## Citing Our Work

If you find our work useful in your research, please consider citing our paper (citation details will be added upon publication).

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
